<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Agent Development Notebook</title>
    <!-- Tailwind CSS for modern, responsive styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <!-- Font Awesome for icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #e5e7eb; /* Light gray background */
        }
        .code-block-container {
            background-color: #1e1e1e; /* VS Code dark theme background */
            color: #d4d4d4; /* VS Code light text color */
            border-radius: 0.5rem;
            padding: 1.5rem;
            overflow-x: auto;
            max-height: 400px;
            /* Scrollbar styling for better readability */
            scrollbar-width: thin;
            scrollbar-color: #6a6a6a #1e1e1e;
        }
        .code-block-container::-webkit-scrollbar {
            height: 8px;
            width: 8px;
        }
        .code-block-container::-webkit-scrollbar-track {
            background: #1e1e1e;
        }
        .code-block-container::-webkit-scrollbar-thumb {
            background-color: #6a6a6a;
            border-radius: 4px;
        }
        .code-block-container pre {
            margin: 0;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        .code-block-container code {
            font-family: 'Fira Code', 'monospace', monospace; /* Monospace font for code */
        }
        h1, h2, h3 {
            font-weight: 700;
        }
        .section-header {
            border-bottom: 2px solid #e5e7eb;
            padding-bottom: 0.5rem;
            margin-bottom: 1rem;
        }
    </style>
</head>
<body class="p-4 sm:p-8">
    <div class="max-w-7xl mx-auto bg-white rounded-lg shadow-xl p-6 md:p-10">
        <header class="mb-8 pb-4 border-b-2 border-gray-200">
            <h1 class="text-4xl font-bold text-gray-900 mb-2">Advanced Agent Development Notebook</h1>
            <p class="text-gray-600">A detailed guide to building comprehensive AI agents with business-focused examples.</p>
        </header>

        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 mb-6">Introduction to Agent Components</h2>
            <p class="text-gray-600 leading-relaxed mb-4">This notebook serves as a comprehensive guide to the key components of an advanced AI agent. We will explore each part's function, business relevance, and technical implementation using detailed, real-world scenarios from the healthcare and retail industries.</p>
        </section>

        <!-- --- Section for Agents --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">1. Agents</h2>
            <p class="text-gray-600 leading-relaxed italic my-4">
                Note: For in-depth how-to guides for agents, please check out LangGraph documentation. The examples here focus on legacy LangChain Agents (`AgentExecutor`). For migration, refer to LangGraph documentation.
            </p>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">In a retail setting, an agent can act as a sophisticated customer service bot. It can understand a customer's request ("Where is my order?"), decide which tools to use (e.g., an API to check order status), and execute a plan to provide a complete answer without human intervention.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Agents solve the problem of requiring static, pre-defined conversational flows. They can handle a much wider range of user queries by dynamically reasoning and chaining together tools, making them adaptable and powerful.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without agents, you would be limited to simple, non-dynamic chatbot logic. The system could not perform complex tasks like fetching real-time data, and would fail on any query that isn't hard-coded, leading to a frustrating user experience.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Custom</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Execution</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">An agent is an execution loop that uses a large language model (LLM) as its 'brain' to reason about which actions to take. The `AgentExecutor` takes an agent and a set of tools and runs the full reasoning process, including parsing the LLM's output to call the correct tool and feeding the tool's result back to the LLM for the final response.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
# How to: use legacy LangChain Agents (AgentExecutor)
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage

# Define a simple tool
@tool
def get_order_status(order_id: str) -> str:
    """Retrieves the current status of a customer's order."""
    if order_id == "ORD123":
        return "Your order has been shipped and is scheduled for delivery tomorrow."
    else:
        return "Order not found."

# Set up the LLM and the prompt
llm = ChatOpenAI(model="gpt-4-turbo", temperature=0)
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful retail assistant. Use the tools to answer questions."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

# Create the agent with the LLM, tools, and prompt
agent = create_openai_tools_agent(llm, [get_order_status], prompt)
agent_executor = AgentExecutor(agent=agent, tools=[get_order_status], verbose=True)

# Run the agent
chat_history = []
user_input = "What's the status of order ORD123?"
response = agent_executor.invoke({"input": user_input, "chat_history": chat_history})
print(response['output'])
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Chat Models --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">2. Chat Models</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">In a banking application, a chat model powers the conversational interface of a virtual assistant. It can understand natural language questions like, "What is my account balance?" or "How do I apply for a loan?" and provide a human-like, multi-turn response.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Chat models are specialized to understand and generate text in a conversational format, a key challenge for chatbots. They excel at maintaining context and producing coherent, engaging dialogue, unlike simpler text completion models.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without chat models, we would have to use basic LLMs, which are not optimized for conversation. The output would likely be less natural, lack conversational flow, and struggle to manage the turn-by-turn context of a dialogue.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Foundation</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">Chat models, such as OpenAI's GPT-4 Turbo or Gemini, are built to work with a list of `Message` objects. This structured input format allows the model to differentiate between system instructions, user queries, and previous AI responses, which is critical for maintaining context in a conversation.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
# A simple example of using a chat model
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

llm = ChatOpenAI(model="gpt-4-turbo", temperature=0)

messages = [
    SystemMessage(content="You are a helpful customer service agent."),
    HumanMessage(content="Hi, what are the opening hours for your main branch?"),
]

response = llm.invoke(messages)

print(response.content)
# "Our main branch is open from 9 AM to 5 PM, Monday through Friday."
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Messages --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">3. Messages</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">In a medical triage application, messages are used to build and maintain a complete conversation history. This allows the system to accurately assess a patient's symptoms over multiple turns, leading to a more precise recommendation for care.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Messages solve the problem of statelessness in large language models. By explicitly providing a history of `HumanMessage` and `AIMessage`, the model can recall past interactions and generate context-aware responses, preventing the conversation from "forgetting" what was just said.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">If messages were not used, every new user prompt would be treated as a brand new conversation. This would make it impossible to have a natural, multi-turn dialogue, as the agent would not remember what it or the user previously said.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Foundation</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">Messages are a core data type in the LangChain framework. They are objects that wrap a string with a `role` (e.g., `system`, `human`, `ai`). This structure is how chat models are designed to process conversational input. `AIMessageChunk` is a special type used for streaming, allowing a message to be built incrementally.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_core.messages import AIMessageChunk

# Create message chunks for streaming
chunk1 = AIMessageChunk(content="I can help")
chunk2 = AIMessageChunk(content=" you with")
chunk3 = AIMessageChunk(content=" that problem.")

# Combine chunks
full_message = chunk1 + chunk2 + chunk3
print(full_message.content)  # "I can help you with that problem."
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Prompt Templates --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">4. Prompt Templates</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A logistics company uses a prompt template to standardize the instructions given to an agent. The template ensures every query for a driver's route includes essential information, like the driver's ID and the time frame, ensuring consistent and accurate responses.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Prompt templates solve the problem of inconsistent and ad-hoc prompting. They provide a reusable, structured way to format prompts, which improves the reliability and quality of the LLM's output. They abstract away the complexity of building the full prompt string.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without templates, you would have to manually construct prompts as raw strings, which is inefficient, error-prone, and difficult to maintain. Slight variations in prompt wording could lead to drastically different and unpredictable results from the LLM.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Custom</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Control</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">A prompt template is a key part of an agent's configuration. It defines the system instructions, the format of the user's input, and how to include conversational history and tool-use scratchpad. The `ChatPromptTemplate` is especially useful for chat models as it allows you to define multiple messages with different roles.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a friendly customer service bot."),
    ("human", "What is your return policy?"),
])

# Use the template to create a prompt
print(prompt.format())
# The output is a list of messages
# [SystemMessage(content='You are a friendly customer service bot.'), HumanMessage(content='What is your return policy?')]

# A more complex template for an agent
agent_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are an agent with access to tools. Use them to answer questions."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Example Selectors --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">5. Example Selectors</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">In a medical coding agent, an example selector provides the agent with a few-shot learning example that is highly relevant to the current patient case. For instance, if the patient has a cardiovascular condition, the selector would provide a pre-written example of a cardiovascular claim, improving the agent's accuracy.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Example selectors address the problem of providing relevant context to the LLM without overwhelming it. Instead of sending a massive list of all possible examples, it intelligently chooses the most semantically similar ones to guide the model's behavior for a specific task.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without example selectors, you would either have to manually hard-code examples (which limits flexibility) or rely on a generic prompt, which might not perform as well on complex or nuanced tasks. This would lead to lower accuracy and more errors in specific domains.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Control</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">An example selector works by taking a pool of examples, converting them into vector embeddings, and then performing a similarity search against the current user query. The most similar examples are then inserted into a `PromptTemplate`. This is a powerful technique for few-shot prompting, especially when the task requires subtle domain-specific knowledge.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate
from langchain.prompts.example_selector import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# A small set of examples for a retail agent
examples = [
    {"query": "Is the new phone in stock?", "answer": "I can check our inventory for the new phone. What is the model number?"},
    {"query": "When will my package arrive?", "answer": "To track your package, please provide your order number."},
    {"query": "What's the best TV for gaming?", "answer": "I can recommend a TV. What is your budget and preferred screen size?"},
]

# Set up the example selector
example_selector = SemanticSimilarityExampleSelector.from_examples(
    examples=examples,
    embeddings=OpenAIEmbeddings(),
    vectorstore=Chroma.from_texts(
        [example["query"] for example in examples], OpenAIEmbeddings()
    ),
    k=1, # Select only the single most similar example
)

# A prompt template to use with the selected examples
example_prompt = PromptTemplate.from_template(
    "User: {query}\nAI: {answer}"
)

# Combine them into a few-shot prompt
few_shot_prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="You are an expert customer service assistant. Use these examples to guide your responses.",
    suffix="User: {input}\nAI:",
    input_variables=["input"]
)

# Example usage
print(few_shot_prompt.format(input="Where's my order?"))
# The selector will pick the "When will my package arrive?" example.
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for LLMs --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">6. LLMs</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A banking compliance team uses an LLM to automatically summarize lengthy regulatory documents and identify key changes. The LLM's core generative capability drastically reduces the time spent on manual review and analysis.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">LLMs are the core of generative AI, solving the fundamental problem of creating new, coherent text from a given prompt. They provide the 'intelligence' for agents and other applications by understanding patterns in vast amounts of data.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without an LLM, the entire field of generative AI agents would not exist. Every task, from simple text generation to complex reasoning, would have to be handled by traditional, rule-based programming, which is brittle and non-scalable.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Foundation</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">LLMs are the raw, text-in and text-out models. While chat models are a specific type of LLM, the term "LLM" can refer to any model that performs text generation based on a prompt. LangChain provides a simple, unified interface for interacting with different LLM providers, abstracting away their unique APIs.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_openai import OpenAI

# The raw LLM interface
llm = OpenAI(model="gpt-3.5-turbo-instruct", temperature=0.7)

# Prompt the model directly
prompt = "Write a short summary of a patient's medical history for a doctor."
response = llm.invoke(prompt)

print(response)
# Note: The output is less structured than a chat model's.
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Output Parsers --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">7. Output Parsers</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A retail agent needs to extract key product details (name, price, stock) from an LLM's text response to update a database. An output parser ensures this information is consistently formatted as a JSON object, making it easy for the application to process.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Output parsers solve the problem of turning unstructured, free-form text from an LLM into a structured data format (like JSON, a list, or a Pydantic object). This is crucial for integrating the LLM's output into programmatic workflows.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without output parsers, you would need to write complex and brittle string parsing logic (e.g., regex) for every LLM response. This would be difficult to maintain and highly prone to failure if the LLM's output format changes slightly.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Control</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">An output parser is a class that takes a string and returns a structured object. The `JsonOutputParser` is particularly useful for agents as it allows the LLM to generate tool calls or final answers in a predictable JSON format. This makes the agent's reasoning more reliable and easier to integrate with other components.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# The Pydantic model defines the expected JSON structure
from pydantic import BaseModel, Field
class ProductDetails(BaseModel):
    product_name: str = Field(description="The name of the product.")
    price: float = Field(description="The price of the product.")
    in_stock: bool = Field(description="Whether the product is currently in stock.")

parser = JsonOutputParser(pydantic_object=ProductDetails)

prompt = PromptTemplate(
    template="Answer the user query.\n{format_instructions}\nQuery: {query}",
    input_variables=["query"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)

model = ChatOpenAI(temperature=0)
chain = prompt | model | parser

# The LLM is instructed to return a JSON object, which is then parsed.
result = chain.invoke({"query": "The new iPhone 15 costs $999 and is currently available."})
print(result)
# {'product_name': 'iPhone 15', 'price': 999.0, 'in_stock': True}
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Document Loaders --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">8. Document Loaders</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">In a legal firm, a document loader ingests thousands of legal contracts from a local directory or a cloud storage service. This allows a legal assistant agent to answer specific questions about contract clauses, saving time and reducing the risk of human error.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Document loaders solve the initial challenge of getting data into the agent's workflow. They provide a standardized way to read content from various sources, such as PDFs, websites, databases, and local files, and convert it into a format that the agent can process.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without document loaders, you would have to write custom code for every data source to extract text. This would be incredibly time-consuming and fragile, as any change to the data source's format would require rewriting the ingestion logic.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Foundation</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">Document loaders are the first step in a Retrieval-Augmented Generation (RAG) pipeline. They take data from a source and load it into a list of `Document` objects. Each document typically contains a page content string and an optional metadata dictionary. This abstraction makes it easy to handle diverse data types.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
# A simple example of using a document loader
from langchain_community.document_loaders import TextLoader

# Assume 'data/policy.txt' is a file with our text
# In a real app, this could be a WebBaseLoader, CSVLoader, etc.
loader = TextLoader("data/policy.txt")
documents = loader.load()

# Each document object has page_content and metadata
print(f"Number of documents loaded: {len(documents)}")
print(f"Content of the first document: {documents[0].page_content[:100]}...")
print(f"Metadata: {documents[0].metadata}")
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Text Splitters --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">9. Text Splitters</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A healthcare agent ingests a large PDF containing a patient's entire medical history. A text splitter breaks this document down into smaller chunks, each containing a single visit's notes or lab results. This allows the vector store to perform more precise searches for specific information.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Text splitters solve the problem of LLM context window limitations. By dividing large documents into smaller, semantically coherent chunks, they ensure that the retrieved information fits within the LLM's token limit, and also that each piece of information is a meaningful unit for retrieval.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without a text splitter, you would either have to feed the entire document to the LLM (which would fail on long documents) or manually split the text, a process that would likely break up sentences and paragraphs in a way that destroys context.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Foundation</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">The `RecursiveCharacterTextSplitter` is a popular choice because it tries to split on different characters (`\n\n`, `\n`, `.`, ` `) in a hierarchical fashion. This method aims to keep semantically related pieces of text together. It also allows you to define a chunk size and an overlap between chunks to maintain context across splits.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Example text
long_text = """
The first section of our policy covers our return guidelines. You can return products within 30 days of purchase for a full refund.
The second section details our shipping policy. Orders placed before 2 PM PST will be shipped on the same day.
"""

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=100,
    chunk_overlap=20,
    length_function=len,
    is_separator_regex=False,
)

chunks = text_splitter.create_documents([long_text])

print(f"Number of chunks created: {len(chunks)}")
for i, chunk in enumerate(chunks):
    print(f"--- Chunk {i+1} ---")
    print(chunk.page_content)
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Embedding Models --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">10. Embedding Models</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A banking agent uses an embedding model to convert all internal financial documents into numerical vectors. When an employee asks about a specific fraud detection protocol, the agent can use the query's vector to find the most relevant documents, even if the exact keywords are not used.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Embedding models solve the problem of semantic search. They convert text into a high-dimensional vector space where the distance between vectors represents the semantic similarity of the original text. This allows for searching based on meaning, not just keywords.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without embedding models, retrieval would be limited to keyword matching, like a simple `Ctrl+F` search. This would miss relevant documents that use different phrasing and would lead to a poor user experience for a RAG-based agent.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Foundation</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">An embedding model is a neural network that maps text to a vector of floating-point numbers. In LangChain, the `OpenAIEmbeddings` class is a common choice. This model is called during the indexing phase of a RAG pipeline to create the vector store and again during the retrieval phase to convert the user's query into a vector for comparison.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_openai import OpenAIEmbeddings

# Initialize the embedding model
embeddings = OpenAIEmbeddings()

# Embed a simple text
text1 = "How is my account balance?"
text2 = "What's the money in my checking account?"
text3 = "What is the capital of France?"

embedding1 = embeddings.embed_query(text1)
embedding2 = embeddings.embed_query(text2)
embedding3 = embeddings.embed_query(text3)

print(f"Embedding length: {len(embedding1)}")
# Note: The vectors for text1 and text2 would be closer in the vector space
# than the vector for text3.
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Vector Stores --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">11. Vector Stores</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A retail company stores product descriptions, customer reviews, and support tickets in a vector store. This allows their internal support agent to quickly find the most similar support tickets to a new customer's problem, providing a quick and relevant solution.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Vector stores solve the problem of efficiently storing and searching high-dimensional vectors. They provide a dedicated database for vector embeddings, enabling fast similarity searches across millions of documents, which is not possible with a traditional relational database.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without a vector store, you would have no scalable way to perform semantic search. All documents would have to be manually searched, or you would be forced to use less efficient, brute-force search methods that would be too slow for any real-world application.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Foundation</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">A vector store is a database optimized for vector similarity search. It uses algorithms like HNSW (Hierarchical Navigable Small World) to quickly find the k-nearest neighbors to a given query vector. LangChain provides a uniform interface to many different vector stores, such as Chroma, FAISS, and Pinecone.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# Create a sample vector store from texts and embeddings
vectorstore = Chroma.from_texts(
    ["The return policy is 30 days.", "Shipping is free for orders over $50."],
    embedding=OpenAIEmbeddings()
)

# Perform a similarity search on the vector store
query = "I need to send something back."
docs = vectorstore.similarity_search(query)

# The result will be the most semantically similar document
print(docs[0].page_content)
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Retrievers --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">12. Retrievers</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A healthcare agent uses a retriever to find relevant patient data from the vector store. When a nurse asks for "Jane Doe's medication list," the retriever fetches documents containing her prescription history, which is then used by the LLM to generate a safe and accurate response.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Retrievers solve the problem of bridging the gap between a user's natural language query and the technical process of searching a vector store. They abstract away the embedding and search process, providing a simple `.get_relevant_documents()` interface that agents can use.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without a retriever, the agent would have to manually handle the embedding of the query, the similarity search, and the formatting of the results. This would make the agent's code more complex and less modular.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Execution</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">A retriever is an abstraction over a vector store. While a vector store is a database, a retriever is an object that can fetch documents from it. The most common type is a `VectorStoreRetriever`. It takes a user query, embeds it, queries the underlying vector store, and returns a list of `Document` objects.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# Create a sample vector store (as above)
vectorstore = Chroma.from_texts(
    ["The return policy is 30 days.", "Shipping is free for orders over $50."],
    embedding=OpenAIEmbeddings()
)

# Create a retriever from the vector store
retriever = vectorstore.as_retriever()

# Use the retriever with a natural language query
query = "How can I return an item?"
retrieved_docs = retriever.get_relevant_documents(query)

print(f"Retrieved document: {retrieved_docs[0].page_content}")
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Indexing --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">13. Indexing</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A logistics company continuously indexes new delivery manifest documents into a vector store. This ensures the agent's knowledge base is always up-to-date with the latest shipment information, allowing it to provide real-time updates to customers and staff.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Indexing solves the problem of keeping the RAG system's knowledge base current. It is the process of loading, splitting, and embedding documents, then storing them in a vector store for efficient retrieval.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">If indexing is not performed, the agent would have no information to retrieve. It would be a "brain" without a memory, unable to answer any questions that require knowledge beyond its initial training data.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Custom</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Foundation</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">Indexing is a pipeline that involves a document loader, text splitter, embedding model, and vector store. The process can be triggered periodically or in response to new data. The following code shows a complete indexing pipeline from a text file to a vector store.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
# A complete indexing pipeline
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# Step 1: Load the data
loader = TextLoader("data/logistics_manifest.txt")
documents = loader.load()

# Step 2: Split the documents into chunks
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = text_splitter.split_documents(documents)

# Step 3: Embed the chunks and create a vector store
embedding_model = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embedding_model,
)

print(f"Successfully indexed {len(chunks)} chunks into the vector store.")
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Tools --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">14. Tools</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A healthcare agent uses a `get_patient_lab_results` tool to make a secure API call to a hospital's lab information system. This allows a doctor to ask the agent, "What were Jane Doe's latest blood test results?" and receive a real-time, accurate response without manually logging into the lab system.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Tools solve the problem of allowing an LLM to interact with the real world. By wrapping functions or APIs in a tool, we give the agent the ability to perform actions, not just generate text. This is what transforms an LLM from a passive text generator into an active, functional agent.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without tools, an agent would be unable to access any real-time, private, or external information. It would be a "closed-world" agent, only capable of answering questions based on its pre-trained data and any documents provided via a RAG system.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Custom</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Interface</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">The `@tool` decorator in LangChain is a convenient way to create a tool from a Python function. It automatically extracts the function's name, docstring (which serves as the tool's description), and parameter types. This structured schema is what the LLM uses to reason about whether to call the tool and what arguments to pass to it.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_core.tools import tool
import requests
from typing import Optional

@tool
def get_customer_credit_score(customer_id: str, api_key: str) -> int:
    """
    Retrieves the current credit score for a banking customer.
    
    Args:
        customer_id: The unique identifier for the customer
        api_key: Secure API key for authentication
        
    Returns:
        The customer's current credit score (300-850)
    """
    # In a real implementation, this would make a secure API call
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # Mocking an API call
    response = requests.post(
        "https://api.bankingsystem.com/credit-score",
        json={"customer_id": customer_id},
        headers=headers
    )
    
    if response.status_code != 200:
        raise Exception(f"API Error: {response.status_code}")
        
    return response.json().get("credit_score")

# The tool can now be used by an agent
print(get_customer_credit_score.name)
print(get_customer_credit_score.description)
print(get_customer_credit_score.args)
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Multimodal --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">15. Multimodal</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A retail agent can receive an image of a damaged product from a customer and a text prompt saying "This product arrived damaged." A multimodal model can process both the text and the image to automatically initiate a refund or replacement process, improving customer service efficiency.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Multimodal capabilities solve the limitation of agents being restricted to text-only input. They allow the agent to understand and reason about information from different modalities, such as images, audio, or video, enabling more complex and human-like interactions.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without multimodal support, the agent would be unable to process visual or auditory information. The customer in our retail example would have to manually describe the damage, a process that is less efficient and less accurate than simply showing a picture.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Foundation</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">A multimodal model can process a list of `Message` objects that contain both text and image content. The image content is typically sent as a base64-encoded string. This allows the model to reason about the image in the context of the text, enabling a wide range of new applications.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
import base64
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# A mock function to encode an image to base64
def image_to_base64(image_path: str) -> str:
    # In a real app, this would read an image file
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

# Assume 'data/damaged_product.png' exists
# base64_image = image_to_base64('data/damaged_product.png')

# We'll use a placeholder for the base64 string
base64_image_placeholder = "..."

# Create a multimodal message
message = HumanMessage(
    content=[
        {"type": "text", "text": "This product arrived damaged. Can you help me?"},
        {
            "type": "image_url",
            "image_url": {"url": f"data:image/png;base64,{base64_image_placeholder}"}
        }
    ]
)

# Use a multimodal model (like a compatible OpenAI model)
# llm = ChatOpenAI(model="gpt-4-vision-preview", max_tokens=1024)
# response = llm.invoke([message])
# print(response.content)
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Callbacks --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">16. Callbacks</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A banking agent uses callbacks to log every step of a transaction process to an internal audit trail. This ensures that every tool call, LLM thought, and final response is recorded for compliance and security purposes.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Callbacks solve the problem of observability. They allow developers to hook into the agent's internal workings, providing visibility into the entire chain of thought and execution. This is essential for debugging, monitoring, and auditing agent behavior.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without callbacks, an agent would be a "black box." You would only see the final input and output, making it extremely difficult to debug why an agent made a particular decision or failed on a specific task.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Custom</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Control</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">A callback handler is a class with methods that are called at various points in the agent's lifecycle (e.g., `on_tool_start`, `on_llm_end`). You can create a custom callback handler to log information, send notifications, or perform other actions based on the agent's internal state. LangChain's `StdOutCallbackHandler` is a simple example that prints the agent's thought process to the console when `verbose=True` is set.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_core.callbacks import BaseCallbackHandler

class CustomCallbackHandler(BaseCallbackHandler):
    """A simple custom callback handler for logging."""
    def on_tool_start(self, serialized: dict, input_str: str, **kwargs: Any) -> None:
        print(f"[Callback] Starting tool: {serialized['name']} with input: {input_str}")
        
    def on_tool_end(self, output: str, **kwargs: Any) -> None:
        print(f"[Callback] Tool ended with output: {output[:50]}...")

# Example agent from a previous section
# ... (llm, tools, prompt, agent, agent_executor definitions) ...

# Running the agent with our custom callback
# from langchain_community.callbacks import get_openai_callback

# with get_openai_callback() as cb:
#     response = agent_executor.invoke(
#         {"input": "What's the status of order ORD123?", "chat_history": []},
#         callbacks=[CustomCallbackHandler()]
#     )
#     print(f"Total tokens used: {cb.total_tokens}")
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Custom --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">17. Custom</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A custom component could be a proprietary `FinancialDatabaseLoader` that securely connects to a bank's legacy system and formats the data for the agent. This custom element ensures the agent can interact with unique, internal systems that are not supported by off-the-shelf components.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Custom components solve the problem of enterprise-specific integration needs. While predefined components cover most common use cases, custom elements allow you to extend the framework's functionality to fit your business's unique data sources, tools, or logic.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without the ability to build custom components, the agent would be limited to a closed set of predefined integrations. This would make it impossible to deploy the agent in an enterprise environment that relies on proprietary or legacy systems.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Custom</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Interface</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">Many of the framework's classes, like `BaseTool`, `BaseDocumentLoader`, or `BaseCallbackHandler`, are designed to be extended. By inheriting from these base classes, you can create custom components that seamlessly integrate with the rest of the agent's architecture, allowing you to tailor the system to your specific needs.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_core.tools import BaseTool

class GetSecurePatientDataTool(BaseTool):
    """Custom tool to retrieve secure patient data."""
    name: str = "get_secure_patient_data"
    description: str = "Retrieves patient data from a secure, internal database."

    def _run(self, patient_id: str) -> str:
        # This method would contain your custom, secure logic.
        if patient_id == "P101":
            return "Patient P101 has an allergy to penicillin and a history of hypertension."
        return "Patient not found."

    async def _arun(self, patient_id: str) -> str:
        # Asynchronous version for better performance in a larger application
        return self._run(patient_id)

# Now this custom tool can be added to the agent's tool list
# custom_tool = GetSecurePatientDataTool()
# tools.append(custom_tool)
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- --- Section for Serialization --- -->
        <hr class="my-10">
        <section class="mb-10">
            <h2 class="text-3xl font-semibold text-gray-800 section-header">18. Serialization</h2>
            <div class="space-y-6">
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚úÖ Business Use Case</h4>
                    <p class="text-gray-600">A development team wants to save the entire agent configuration (including its prompt, tools, and a defined chain) as a single JSON file. This serialized file can then be easily shared, version-controlled, or deployed to a production environment without having to rebuild the entire object in code.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ùå Problems Solved</h4>
                    <p class="text-gray-600">Serialization solves the problem of persistence and reproducibility. It provides a way to convert complex Python objects (like agents or chains) into a storable, shareable format. This is critical for moving from development to production and for maintaining a stable, versioned codebase.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">‚ö†Ô∏è Impact if Absent</h4>
                    <p class="text-gray-600">Without serialization, every time you want to run the agent, you would have to recreate all its components from scratch in memory. This would make deployment difficult, version control impossible, and sharing configurations with a team extremely cumbersome.</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîß Predefined or Custom</h4>
                    <p class="text-gray-600">Predefined</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üîó Relationship Keyword</h4>
                    <p class="text-gray-600">Control</p>
                </div>
                <div class="p-6 bg-gray-50 rounded-lg">
                    <h4 class="text-xl font-bold text-gray-800 mb-2">üß† In-depth Technical Insight</h4>
                    <p class="text-gray-600">Many of the objects in LangChain have `dumpd()` and `load()` methods that handle serialization and deserialization. This allows you to convert the object into a dictionary (which can be saved as JSON) and then load it back into the original object. The following example shows how to serialize and deserialize a simple prompt template.</p>
                    <div class="code-block-container mt-4">
                        <pre><code class="language-python">
from langchain_core.prompts import PromptTemplate
import json

# Create a prompt template
prompt = PromptTemplate(
    input_variables=["topic"],
    template="Create a short story about a character who discovers a magical {topic}."
)

# Serialize the prompt to a dictionary
serialized_prompt = prompt.dumpd()
print("--- Serialized Dictionary ---")
print(json.dumps(serialized_prompt, indent=2))

# Save to a file
with open("story_prompt.json", "w") as f:
    json.dump(serialized_prompt, f, indent=2)

# Load the prompt from the serialized data
# from langchain_core.prompts import load_prompt
# with open("story_prompt.json", "r") as f:
#     loaded_prompt = load_prompt(f)

# print("\n--- Loaded Prompt ---")
# print(loaded_prompt.format(topic="book"))
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>
        
        <footer class="mt-12 pt-6 border-t-2 border-gray-200 text-center text-gray-500 text-sm">
            &copy; 2024 Advanced Agent Development Notebook. All rights reserved.
        </footer>
    </div>
</body>
</html>
